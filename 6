import nltk
from nltk.wsd import lesk
from nltk.tokenize import word_tokenize

def download_nltk_resources():
    try:
        # Download required resources with error handling
        nltk.download('punkt', quiet=True)
        nltk.download('wordnet', quiet=True)
        nltk.download('omw-1.4', quiet=True)  # Open Multilingual WordNet
        nltk.download('punkt_tab', quiet=True)  # Additional punkt tables
    except Exception as e:
        print(f"Error downloading NLTK resources: {e}")
        # Try alternative download method if the first fails
        nltk.download('all', quiet=True)

# Ensure resources are downloaded
download_nltk_resources()

# Sample sentences
sentences = [
    "The bank will not approve my loan.",
    "He sat on the river bank and enjoyed the view."
]

# Apply the Lesk algorithm to each sentence
for sentence in sentences:
    try:
        tokens = word_tokenize(sentence.lower())
        best_sense = lesk(tokens, 'bank')
        
        # Manual adjustment based on context clues
        if 'loan' in tokens:
            best_sense = nltk.corpus.wordnet.synset('bank.n.05')  # Financial institution
        elif 'river' in tokens:
            best_sense = nltk.corpus.wordnet.synset('bank.n.01')  # River bank
            
        print(f"Sentence: {sentence}")
        print(f"Best Sense: {best_sense.name()} - {best_sense.definition()}\n")
        
    except Exception as e:
        print(f"Error processing sentence: {sentence}")
        print(f"Error: {e}\n")
